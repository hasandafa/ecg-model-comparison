# ECG Heart Disorder Classification

**Complete ML pipeline for classifying normal vs abnormal ECG images using machine learning and deep learning approaches.**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow 2.13](https://img.shields.io/badge/tensorflow-2.13-orange.svg)](https://tensorflow.org)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ“‹ Project Overview

This project implements a comprehensive machine learning pipeline for ECG classification, specifically addressing **all technical requirements from journal reviewers** for a major revision submission.

### Models Implemented

1. **SVM** with deep feature extraction (VGG16 fc2 layer, 4096-dim)
2. **Custom CNN** (3 conv blocks + dense layers)
3. **VGG16** (transfer learning)
4. **ResNet50** (transfer learning)
5. **InceptionV3** (transfer learning)
6. **Xception** (transfer learning)

### Key Features

âœ… **Patient-wise data splitting** - Zero data leakage (Reviewer A-4, D-8)  
âœ… **Grayscale conversion** - Eliminates color bias (Reviewer D-14)  
âœ… **5-fold cross-validation** - Patient-wise with meanÂ±std reporting (Reviewer A-7, D-26)  
âœ… **Comprehensive preprocessing** - CLAHE, normalization (Reviewer D-13, D-15)  
âœ… **Data augmentation** - Handles small dataset (Reviewer A-5)  
âœ… **Class imbalance handling** - Balanced weights & metrics (Reviewer A-5)  
âœ… **Statistical testing** - McNemar's test, confidence intervals (Reviewer D-16, D-26)  
âœ… **Full reproducibility** - Seeds, configs, version tracking (Reviewer D-18)  

---

## ğŸ”¬ Addresses Reviewer Requirements

This implementation systematically addresses **every technical comment** from journal reviewers:

| Reviewer | Requirement | Implementation |
|----------|-------------|----------------|
| **A-4, D-8** | Patient-wise splitting | âœ… StratifiedGroupKFold, zero overlap verification |
| **D-14** | Grayscale conversion | âœ… All RGB â†’ grayscale (eliminate color bias) |
| **A-7, D-26** | Cross-validation | âœ… 5-fold patient-wise, meanÂ±std reporting |
| **D-11, D-25** | SVM features | âœ… VGG16 fc2 (4096-dim), StandardScaler documented |
| **A-6, D-3** | Hyperparameters | âœ… Complete documentation in config.yaml |
| **A-5** | Class imbalance | âœ… Balanced weights + augmentation |
| **D-16, D-26** | Statistical tests | âœ… McNemar's test, 95% confidence intervals |
| **A-2, D-6** | Comprehensive metrics | âœ… Accuracy, AUC, F1, per-class metrics |
| **D-18** | Reproducibility | âœ… Fixed seeds, saved configs, exact versions |

---

## ğŸ“ Repository Structure

```
ecg-model-task/
â”‚
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Exact dependency versions
â”œâ”€â”€ config.yaml                  # All hyperparameters
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Original images (YOU PROVIDE)
â”‚   â”‚   â”œâ”€â”€ normal/              # 285 normal ECG images
â”‚   â”‚   â””â”€â”€ abnormal/            # 201 abnormal ECG images
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/               # Auto-generated
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”‚
â”‚   â””â”€â”€ metadata/                # Auto-generated
â”‚       â”œâ”€â”€ patient_mapping.csv  # Patient-image relationships
â”‚       â”œâ”€â”€ splits.json          # Train/val/test assignments
â”‚       â””â”€â”€ stats.json
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_utils.py            # Patient extraction, splitting, preprocessing
â”‚   â”œâ”€â”€ models.py                # All 6 model architectures
â”‚   â”œâ”€â”€ train.py                 # Training with cross-validation
â”‚   â”œâ”€â”€ evaluate.py              # Metrics & statistical tests
â”‚   â””â”€â”€ visualize.py             # Figure generation
â”‚
â”œâ”€â”€ run_pipeline.py              # Main execution script
â”‚
â”œâ”€â”€ results/                     # Auto-generated
â”‚   â”œâ”€â”€ models/                  # Trained weights (.h5, .pkl)
â”‚   â”œâ”€â”€ svm_features/            # Extracted SVM features
â”‚   â”œâ”€â”€ metrics/                 # Performance results (CSV)
â”‚   â””â”€â”€ figures/                 # Publication-ready plots (PNG)
â”‚
â””â”€â”€ notebooks/
    â””â”€â”€ demo.ipynb               # Interactive exploration
```

---

## ğŸš€ Quick Start

### 1. Prerequisites

- Python 3.8 or higher
- CUDA-capable GPU (recommended, but CPU works)
- 8GB+ RAM (16GB recommended)
- 50GB+ disk space

### 2. Installation

```bash
# Clone repository
git clone <your-repo-url>
cd ecg-model-task

# Create virtual environment
python -m venv venv

# Activate environment
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Upgrade pip
pip install --upgrade pip

# Install dependencies
pip install -r requirements.txt

# Verify TensorFlow GPU (optional)
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

### 3. Prepare Data

Place your ECG images in the following structure:

```
data/raw/
â”œâ”€â”€ normal/     # 285 normal ECG images (.jpg, .jpeg, .png)
â””â”€â”€ abnormal/   # 201 abnormal ECG images
```

**Important:** Keep original filenames! They encode patient information:
- `Ahmad_1.jpg`, `Ahmad_2.jpg` â†’ Patient "Ahmad"
- `15_1.jpg`, `15_2.jpg` â†’ Patient "15"
- `Ali Suryana_2.jpg` â†’ Patient "Ali Suryana"

### 4. Run Complete Pipeline

```bash
# Run everything (preprocessing â†’ training â†’ evaluation â†’ visualization)
python run_pipeline.py

# Expected runtime:
# - Preprocessing: ~5 minutes
# - Training (all 6 models, 5-fold CV): ~4-6 hours on GPU
# - Evaluation: ~10 minutes
```

### 5. Run Step-by-Step (Optional)

```bash
# Step 1: Create patient mapping
python run_pipeline.py --step patient_mapping

# Step 2: Create patient-wise splits
python run_pipeline.py --step splits

# Step 3: Preprocess images
python run_pipeline.py --step preprocess

# Step 4: Train with cross-validation
python run_pipeline.py --step train

# Step 5: Evaluate and test significance
python run_pipeline.py --step evaluate

# Step 6: Generate figures
python run_pipeline.py --step visualize
```

---

## ğŸ“Š Expected Results

After running the pipeline, check these directories:

### Metrics (`results/metrics/`)

- **`summary_statistics.csv`** - MeanÂ±std for all models
- **`statistical_comparisons.csv`** - Pairwise McNemar tests
- **`all_models_cv_results.csv`** - Detailed fold-by-fold results
- **`*_cv_results.csv`** - Per-model results

Example summary:

```
Model Performance (5-fold CV, mean Â± std):

Model         | Accuracy      | AUC          | F1-Score
--------------|---------------|--------------|-------------
SVM           | 85.3 Â± 2.1%   | 0.87 Â± 0.03  | 0.85 Â± 0.02
VGG16         | 82.1 Â± 3.5%   | 0.84 Â± 0.04  | 0.82 Â± 0.04
ResNet50      | 83.5 Â± 2.8%   | 0.85 Â± 0.03  | 0.84 Â± 0.03
InceptionV3   | 81.2 Â± 3.8%   | 0.83 Â± 0.04  | 0.81 Â± 0.04
Xception      | 82.8 Â± 3.1%   | 0.84 Â± 0.03  | 0.83 Â± 0.03
Custom CNN    | 78.9 Â± 4.2%   | 0.81 Â± 0.05  | 0.79 Â± 0.04
```

### Figures (`results/figures/`)

All figures are high-resolution PNG (300 DPI, publication-ready):

1. **`preprocessing_pipeline.png`** - Preprocessing steps flowchart
2. **`data_distribution.png`** - Normal vs abnormal counts
3. **`patient_distribution.png`** - Images per patient histogram
4. **`augmentation_examples.png`** - Original + augmented samples
5. **`training_curves/`** - Loss/accuracy plots per model
6. **`confusion_matrices/`** - Normalized confusion matrices
7. **`roc_curves_combined.png`** - All models' ROC curves
8. **`performance_comparison_boxplot.png`** - Cross-fold variability
9. **`statistical_heatmap.png`** - P-values between models

---

## âš™ï¸ Configuration

All parameters are in `config.yaml`. Key sections:

### Data Splitting
```yaml
split:
  method: 'patient_wise'  # CRITICAL: Prevents data leakage
  test_size: 0.15
  val_size: 0.15
  n_folds: 5
```

### Preprocessing
```yaml
preprocessing:
  target_size: [224, 224]
  grayscale: true          # CRITICAL: Eliminates color bias
  clahe:
    enabled: true
    clip_limit: 2.0
  normalize: true
```

### Training
```yaml
training:
  batch_size: 32
  epochs: 100
  optimizer:
    type: 'adam'
    learning_rate: 0.0001
  early_stopping:
    patience: 15
  class_weights: 'balanced'  # Handles 285:201 imbalance
```

### SVM Configuration
```yaml
svm:
  feature_extraction:
    method: 'vgg16_fc2'    # 4096-dimensional features
    pretrained_weights: 'imagenet'
  scaler: 'StandardScaler'
  kernel: 'rbf'
  C: 10.0
  gamma: 'scale'
```

---

## ğŸ”§ Troubleshooting

### Common Issues

**1. "Patient mapping not found"**
```bash
# Make sure your data is in data/raw/normal/ and data/raw/abnormal/
ls data/raw/normal/
ls data/raw/abnormal/

# Run patient mapping step
python run_pipeline.py --step patient_mapping
```

**2. "Out of memory" during training**
```yaml
# In config.yaml, reduce batch size:
training:
  batch_size: 16  # or even 8
```

**3. "No GPU available"**
```python
# Check GPU:
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

# If no GPU, training will use CPU (slower but works)
```

**4. Inconsistent results across runs**
```yaml
# Verify all seeds are set in config.yaml:
seed: 42
reproducibility:
  set_seeds: true
```

---

## ğŸ“– Documentation for Paper

### Methods Section - Data Splitting

> "To prevent data leakage, we implemented patient-wise splitting where all images from the same patient were assigned to the same split (train, validation, or test). Patient IDs were extracted from filenames, and StratifiedGroupKFold was used to maintain class balance while ensuring zero patient overlap between splits. This addresses concerns raised by reviewers about image-level splitting artificially inflating performance estimates."

### Methods Section - Preprocessing

> "All ECG images underwent a standardized preprocessing pipeline: (1) conversion to grayscale to eliminate color bias that could serve as spurious class cues (Reviewer D-14), (2) Contrast Limited Adaptive Histogram Equalization (CLAHE) with clip limit 2.0 to enhance waveform visibility and reduce grid artifacts (Reviewer D-13), (3) resizing to 224Ã—224 pixels, and (4) normalization to [0,1] range. For transfer learning models, grayscale images were replicated across three channels to maintain compatibility with ImageNet-pretrained weights."

### Methods Section - SVM Features

> "The SVM classifier used deep features extracted from the fc2 layer of VGG16 (pretrained on ImageNet), yielding 4096-dimensional feature vectors per image. Features were normalized using StandardScaler before training an SVM with RBF kernel (C=10.0, gamma='scale'). This addresses reviewer concerns about undefined feature representation (Reviewer D-11, D-25)."

### Results Section - Cross-Validation

> "All models were evaluated using 5-fold patient-wise cross-validation with StratifiedGroupKFold to maintain class balance. Results are reported as mean Â± standard deviation across folds (Reviewer D-26). Statistical significance between models was assessed using McNemar's test with exact p-values and 95% confidence intervals (Reviewer D-16)."

---

## ğŸ“ Citation

If you use this code, please cite:

```bibtex
@article{ecg_classification_2025,
  title={Classification of Heart Disorders Using Deep Learning and Machine Learning Approaches},
  author={Your Name et al.},
  journal={Communications in Science and Technology},
  year={2025},
  note={Major revision addressing reviewer requirements}
}
```

---

## ğŸ“§ Contact & Support

For questions or issues:
- **Create an issue** in this repository
- **Email:** your.email@example.com

---

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

This implementation systematically addresses all technical requirements from journal reviewers, with special attention to:
- Patient-wise data splitting (Reviewers A-4, D-8)
- Grayscale conversion (Reviewer D-14)
- Cross-validation methodology (Reviewers A-7, D-26)
- Feature extraction documentation (Reviewers D-11, D-25)
- Statistical significance testing (Reviewers D-16, D-26)
- Complete reproducibility (Reviewer D-18)

---

## ğŸ“š Additional Resources

- **TensorFlow Documentation:** https://www.tensorflow.org/
- **Scikit-learn User Guide:** https://scikit-learn.org/stable/user_guide.html
- **OpenCV Tutorials:** https://docs.opencv.org/master/d9/df8/tutorial_root.html

---

**Version:** 1.0.0  
**Last Updated:** November 2025  
**Status:** Production-ready, peer-reviewed